# Basic Machine Learning Steps

* Clean up dataset (E.g. do you need EMPLID column?)
* Partition data into training and test dataset. (e.g. 33% for test data)  you can create verification dataset which could not be included in those set.
* Train algorithm (e.g. Either Bayse or DTree)
* Apply Prediction using the test dataset
* Evaluate / Score accuracy, and build Confusion Matrix. Accuracy? Precision? etc...

# Naive Bayse 

- Assume the independence of attributes. Assume each attributes are not related each other.
- Even this assumption is violated, it works well
- Problem happens if repeatitive attributes happen many times because they increase 
the significance for the group
- If the library (e.g. python) does not take categorical value, assign some integer to each class.

see iris_naive.svg for knime sample work flow

# Decision Tree

Decision Tree algorithm take attributes as node. The goal is to construct MINIMUM size of the decision tree.

Use Information Gain (Entropy) or Gini Index to determine which attributes could be the best node to begin with.

* High Entropy - Equaly spreaded out data. E.g. Random Numbers
* Low Entropy - Skewed data set. E.g. 99% of values are falling into one category, it's called lower entropy.

see iris_decision_tree.svg for knime. It's a bit trickey because without statistics node, it would not generate categorizing results. 
Which end up with you get no color. It's counter intuitive because
knime put it for the output from the read file node, not intermediate node in between. Some useful nodes example here to view data.

# Association Rules

Take a lot of market basket type of data:

- item1, item2, item3, ... in column
- Each row indicates the customer purchase "bit"

KNIME minimum workflow requires to use "Bit Vector" node because the spreadsheet value has to be converted as 1 or 0. (e.g. t->1 and (blank)->0)

Association rules will be generated by identifying combination of purchased items. The parameter could be:

Set precondition such as "Find multiple occurance of at least N items purchased together". For example, if a customer purchased meat,milk, and egg, 
the algorithm should look for another customer who purchased same combination of items. 

- Minimum Item Sets ... set threthold. Obviously, look for 2 items combo might be useless but if you increase the number, you would not find any  repeatition.
- Support = Frequency = Occurance freq(x) :  / N
- Confidence = Accuracy: supp(x,y) / supp(x)
- Lift - enhance modeling : supp(x,y) / (supp(x) * supp(y))

# References

See Examples in knime. 

Assoc rules
https://www.knime.org/blog/market-basket-analysis-and-recommendation-engines
