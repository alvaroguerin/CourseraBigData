## Summary

1. Create Mapper and Reducer Files
2. Give permissions
3. Put input files into a hdfs folder
4. Run hadoop command and load .jar file with input dir and outoput dir
5. Get the file back

## Mapper and Reducer

* wordcount_mapper.py
* wordcount_reducer.py

## Test python program
```
cat input.txt | python wordcount_mapper.py | sort > mapped.txt
cat mapped.txt | python wordcount_reducer.py
```
## Upload files

```
```

## Run Map / Reduce

```
```

## Check the results

```
```

## Download output

```
```



